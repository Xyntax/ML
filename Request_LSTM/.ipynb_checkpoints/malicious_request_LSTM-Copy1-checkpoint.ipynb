{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas\n",
    "import numpy\n",
    "import optparse\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv('./data/dev-access.csv', engine='python', quotechar='|', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"timestamp\":1502738402847,\"method\":\"post\",\"qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"timestamp\":1502738402849,\"method\":\"post\",\"qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"timestamp\":1502738402852,\"method\":\"post\",\"qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"timestamp\":1502738402852,\"method\":\"post\",\"qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"timestamp\":1502738402853,\"method\":\"post\",\"qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{\"timestamp\":1502738402853,\"method\":\"post\",\"qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{\"timestamp\":1502738402854,\"method\":\"post\",\"qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{\"timestamp\":1502738402855,\"method\":\"post\",\"qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{\"timestamp\":1502738402856,\"method\":\"post\",\"qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{\"timestamp\":1502738402856,\"method\":\"post\",\"qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  {\"timestamp\":1502738402847,\"method\":\"post\",\"qu...  0\n",
       "1  {\"timestamp\":1502738402849,\"method\":\"post\",\"qu...  0\n",
       "2  {\"timestamp\":1502738402852,\"method\":\"post\",\"qu...  0\n",
       "3  {\"timestamp\":1502738402852,\"method\":\"post\",\"qu...  0\n",
       "4  {\"timestamp\":1502738402853,\"method\":\"post\",\"qu...  0\n",
       "5  {\"timestamp\":1502738402853,\"method\":\"post\",\"qu...  0\n",
       "6  {\"timestamp\":1502738402854,\"method\":\"post\",\"qu...  0\n",
       "7  {\"timestamp\":1502738402855,\"method\":\"post\",\"qu...  0\n",
       "8  {\"timestamp\":1502738402856,\"method\":\"post\",\"qu...  0\n",
       "9  {\"timestamp\":1502738402856,\"method\":\"post\",\"qu...  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = dataframe.sample(frac=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess dataset\n",
    "X = dataset[:,0]\n",
    "Y = dataset[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ '{\"timestamp\":1502738602036,\"method\":\"get\",\"query\":{\"query\":\"Tops&_method=PUT\"},\"path\":\"/search\",\"statusCode\":404,\"source\":{\"remoteAddress\":\"22.148.143.9\",\"referer\":\"http://localhost:8002/enter\"},\"route\":\"/search\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"accept\":\"*/*\",\"cache-control\":\"no-cache\",\"x-requested-with\":\"XMLHttpRequest\",\"referer\":\"http://localhost:8002/enter\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\"},\"requestPayload\":null,\"responsePayload\":{\"statusCode\":404,\"error\":\"Not Found\",\"message\":\"Not Found\"}}',\n",
       "       '{\"timestamp\":1502738461497,\"method\":\"get\",\"query\":{\"query\":\"etudzum\"},\"path\":\"/search\",\"statusCode\":404,\"source\":{\"remoteAddress\":\"81.27.152.121\"},\"route\":\"/search\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"cache-control\":\"no-cache\",\"accept\":\"*/*\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\"},\"requestPayload\":null,\"responsePayload\":{\"statusCode\":404,\"error\":\"Not Found\",\"message\":\"Not Found\"}}',\n",
       "       '{\"timestamp\":1502738585782,\"method\":\"get\",\"query\":{\"query\":\"Area & Accent Rugs/*\"},\"path\":\"/search\",\"statusCode\":404,\"source\":{\"remoteAddress\":\"251.8.39.54\"},\"route\":\"/search\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"cache-control\":\"no-cache\",\"accept\":\"*/*\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\"},\"requestPayload\":null,\"responsePayload\":{\"statusCode\":404,\"error\":\"Not Found\",\"message\":\"Not Found\"}}',\n",
       "       ...,\n",
       "       '{\"timestamp\":1502738590561,\"method\":\"get\",\"query\":{\"query\":\"Watering Equipment&_method=POST&isAdmin=true\"},\"path\":\"/search\",\"statusCode\":404,\"source\":{\"remoteAddress\":\"99.98.90.102\",\"referer\":\"http://localhost:8002/enter\"},\"route\":\"/search\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"accept\":\"*/*\",\"cache-control\":\"no-cache\",\"x-requested-with\":\"XMLHttpRequest\",\"referer\":\"http://localhost:8002/enter\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\"},\"requestPayload\":null,\"responsePayload\":{\"statusCode\":404,\"error\":\"Not Found\",\"message\":\"Not Found\"}}',\n",
       "       '{\"timestamp\":1502738403024,\"method\":\"get\",\"query\":{},\"path\":\"/PMA2013\",\"statusCode\":404,\"source\":{\"remoteAddress\":\"243.15.81.191\",\"referer\":\"http://localhost:8002/enter\"},\"route\":\"/{p*}\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"accept\":\"*/*\",\"cache-control\":\"no-cache\",\"x-requested-with\":\"XMLHttpRequest\",\"referer\":\"http://localhost:8002/enter\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\"},\"requestPayload\":null,\"responsePayload\":{\"statusCode\":404,\"error\":\"Not Found\",\"message\":\"Not Found\"}}',\n",
       "       '{\"timestamp\":1502738643645,\"method\":\"post\",\"query\":{},\"path\":\"/login\",\"statusCode\":200,\"source\":{\"remoteAddress\":\"77.11.74.111\"},\"route\":\"/login\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"cache-control\":\"no-cache\",\"accept\":\"*/*\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\",\"content-type\":\"application/json\",\"content-length\":\"52\"},\"requestPayload\":{\"username\":\"Herb2\",\"password\":\"pizzaloaflasdf0v32\"},\"responsePayload\":\"LOGIN\"}'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, item in enumerate(X):\n",
    "        # Quick hack to space out json elements\n",
    "        reqJson = json.loads(item, object_pairs_hook=OrderedDict)\n",
    "        del reqJson['timestamp']\n",
    "        del reqJson['headers']\n",
    "        del reqJson['source']\n",
    "        del reqJson['route']\n",
    "        del reqJson['responsePayload']\n",
    "        X[index] = json.dumps(reqJson, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ '{\"method\":\"get\",\"query\":{\"query\":\"Tops&_method=PUT\"},\"path\":\"/search\",\"statusCode\":404,\"requestPayload\":null}',\n",
       "       '{\"method\":\"get\",\"query\":{\"query\":\"etudzum\"},\"path\":\"/search\",\"statusCode\":404,\"requestPayload\":null}',\n",
       "       '{\"method\":\"get\",\"query\":{\"query\":\"Area & Accent Rugs/*\"},\"path\":\"/search\",\"statusCode\":404,\"requestPayload\":null}',\n",
       "       ...,\n",
       "       '{\"method\":\"get\",\"query\":{\"query\":\"Watering Equipment&_method=POST&isAdmin=true\"},\"path\":\"/search\",\"statusCode\":404,\"requestPayload\":null}',\n",
       "       '{\"method\":\"get\",\"query\":{},\"path\":\"/PMA2013\",\"statusCode\":404,\"requestPayload\":null}',\n",
       "       '{\"method\":\"post\",\"query\":{},\"path\":\"/login\",\"statusCode\":200,\"requestPayload\":{\"username\":\"Herb2\",\"password\":\"pizzaloaflasdf0v32\"}}'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='\\t\\n', char_level=True)\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract and save word dictionary\n",
    "word_dict_file = 'build/word-dictionary.json'\n",
    "\n",
    "if not os.path.exists(os.path.dirname(word_dict_file)):\n",
    "    os.makedirs(os.path.dirname(word_dict_file))\n",
    "\n",
    "with open(word_dict_file, 'w') as outfile:\n",
    "    json.dump(tokenizer.word_index, outfile, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16,\n",
       " 1,\n",
       " 19,\n",
       " 2,\n",
       " 3,\n",
       " 13,\n",
       " 7,\n",
       " 11,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 28,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 15,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 14,\n",
       " 1,\n",
       " 4,\n",
       " 16,\n",
       " 1,\n",
       " 15,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 14,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 36,\n",
       " 7,\n",
       " 18,\n",
       " 6,\n",
       " 32,\n",
       " 62,\n",
       " 19,\n",
       " 2,\n",
       " 3,\n",
       " 13,\n",
       " 7,\n",
       " 11,\n",
       " 37,\n",
       " 26,\n",
       " 72,\n",
       " 36,\n",
       " 1,\n",
       " 17,\n",
       " 10,\n",
       " 1,\n",
       " 18,\n",
       " 5,\n",
       " 3,\n",
       " 13,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 24,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 23,\n",
       " 13,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 25,\n",
       " 7,\n",
       " 11,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 22,\n",
       " 20,\n",
       " 22,\n",
       " 10,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 15,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 26,\n",
       " 5,\n",
       " 14,\n",
       " 12,\n",
       " 7,\n",
       " 5,\n",
       " 11,\n",
       " 1,\n",
       " 4,\n",
       " 21,\n",
       " 8,\n",
       " 12,\n",
       " 12,\n",
       " 17]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words = len(tokenizer.word_index)+1\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_log_length = 1024\n",
    "train_size = int(len(dataset) * .75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# padding\n",
    "X_processed = sequence.pad_sequences(X, maxlen=max_log_length)\n",
    "# 划分样本集\n",
    "X_train, X_test = X_processed[0:train_size], X_processed[train_size:len(X_processed)]\n",
    "Y_train, Y_test = Y[0:train_size], Y[train_size:len(Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb_callback = TensorBoard(log_dir='./logs', embeddings_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 32, input_length=max_log_length))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64, recurrent_dropout=0.5))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1024, 32)          2816      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024, 32)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 27,713\n",
      "Trainable params: 27,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15059 samples, validate on 5020 samples\n",
      "Epoch 1/3\n",
      "15059/15059 [==============================] - 452s - loss: 0.5981 - acc: 0.6662 - val_loss: 0.3296 - val_acc: 0.8990\n",
      "Epoch 2/3\n",
      "15059/15059 [==============================] - 454s - loss: 0.2738 - acc: 0.9179 - val_loss: 0.1216 - val_acc: 0.9783\n",
      "Epoch 3/3\n",
      "15059/15059 [==============================] - 621s - loss: 0.1647 - acc: 0.9618 - val_loss: 0.0631 - val_acc: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12772c890>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_split=0.25, epochs=3, batch_size=128, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6694/6694 [==============================] - 64s    \n",
      "Model Accuracy: 99.12%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "score, acc = model.evaluate(X_test, Y_test, verbose=1, batch_size=128)\n",
    "print(\"Model Accuracy: {:0.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save_weights('securitai-lstm-weights.h5')\n",
    "model.save('securitai-lstm-model.h5')\n",
    "with open('securitai-lstm-model.json', 'w') as outfile:\n",
    "    outfile.write(model.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evalute 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试另外一个WAF的数据集\n",
    "https://github.com/faizann24/Fwaf-Machine-Learning-driven-Web-Application-Firewall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_black = pandas.read_csv('/Users/xy/workspace/Fwaf-Machine-Learning-driven-Web-Application-Firewall/badqueries.txt',engine='python',sep='!@#$%^&*',header=0)\n",
    "df_white = pandas.read_csv('/Users/xy/workspace/Fwaf-Machine-Learning-driven-Web-Application-Firewall/goodqueries.txt',engine='python',sep='!@#$%^&*',header=0).sample(n=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_black['label'] = 1\n",
    "df_white['label'] = 0\n",
    "new_dataset = df_black.append(df_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_dataset = new_dataset.sample(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_waf = new_dataset['uri'].values.astype('str')\n",
    "Y_waf = new_dataset['label'].values.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sequences = tokenizer.texts_to_sequences(X_waf)\n",
    "X_processed = sequence.pad_sequences(X_sequences, maxlen=max_log_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 97s    \n",
      "Model Accuracy: 73.52%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "score, acc = model.evaluate(X_processed, Y_waf, verbose=1, batch_size=128)\n",
    "print(\"Model Accuracy: {:0.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
